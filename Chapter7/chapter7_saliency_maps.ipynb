{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab930db2-3600-472b-b52c-07ab04866ee8",
   "metadata": {},
   "source": [
    "# Chapter 7 - Backpropagation Versus Perturbation Explainability\n",
    "\n",
    "**Saliency Maps** are backpropagation-based XAI technique that extracts Region of Interest (ROI) and highlights feature importance to human visual perception. This sample notebook is tested with TensorFlow 2.10.1 and Python 3.9.10 using Amazon SageMaker Studio ml.m5.large general-purpose instance with 2 vCPU and 8 GiB. Here is the [link](https://aws.amazon.com/sagemaker/pricing/) regarding instance pricing reference. Alternatively, you can try this on your preferred IDE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235bb523-1fe3-456c-8c81-8818782d1008",
   "metadata": {},
   "source": [
    "## Install and Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576f7ca-bb25-45c8-aef3-e595f997c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install essential libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from platform import python_version\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# Validate dependencies\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'Python version: {python_version()}')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357ee1c-320b-465b-a297-b5b2e59c3ba8",
   "metadata": {},
   "source": [
    "## Load a Pre-trained Model\n",
    "\n",
    "We will load a VGG16 image classification model with pre-trained weights on ImageNet and view a summary of the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d820363-7bf6-49ae-9318-cf40b0059fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.VGG16(weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7fd93-db5e-4fc4-a921-05edf362b91a",
   "metadata": {},
   "source": [
    "## Load and Predict an Image\n",
    "\n",
    "Load a sample input shape, set the target input size, and obtain predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc74615-f94f-4547-9c6a-7da38715794d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a sample image and set target input size\n",
    "\n",
    "img_path = 'panda.jpeg'\n",
    "\n",
    "image = tf.keras.utils.load_img(img_path, target_size=(224,224))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c36bf-4f8b-44d8-9e18-67667e59e068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess image and obtain a prediction\n",
    "\n",
    "img = tf.keras.utils.img_to_array(image)\n",
    "img = img.reshape((1, *img.shape))\n",
    "y_pred = model.predict(img)\n",
    "\n",
    "# Top 5 predicted classes\n",
    "top5 = tf.keras.applications.vgg16.decode_predictions(y_pred, top=5)\n",
    "print('Top 5 classes:')\n",
    "top5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f307ddd1-d326-432c-8b63-783a61cbe722",
   "metadata": {},
   "source": [
    "## Calculate Gradients\n",
    "\n",
    "TensorFlow provides tf.GradientTape API for automatic differentiation or autodiff to evaluate gradients with respect to the context within tf.GradientTape via backpropagation. Let's compute the gradients for the top class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a544b6-9310-4464-ae16-1004915f4bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute gradients contributing to the top class\n",
    "\n",
    "images = tf.Variable(img, dtype=float)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    pred = model(images, training=False)\n",
    "    sorted_class = np.argsort(pred.numpy().flatten())[::-1]\n",
    "    loss = pred[0][sorted_class[0]]\n",
    "\n",
    "grads = tape.gradient(loss, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f415c587-36f1-4c86-ad21-7cad4cdc9236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find the max of absolute values of gradients to determine saliency map\n",
    "\n",
    "grads_abs = tf.math.abs(grads)\n",
    "grads_max = np.max(grads_abs, axis=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9855828-ea48-4af9-b010-cdd239b65ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize the gradients\n",
    "\n",
    "gmin, gmax  = np.min(grads_max), np.max(grads_max)\n",
    "grads_eval = (grads_max - gmin) / (gmax - gmin + 1e-18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161b975-b81a-486a-8094-a8e16d8b6bb0",
   "metadata": {},
   "source": [
    "## Visualize Saliency Maps\n",
    "\n",
    "We can see the panda's eyes and nose contribute to the feature importance score to its predicted class as a giant panda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bdca0c-ca82-4ed4-8e98-d924a8e3cccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create and visualize salience maps\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(20,7))\n",
    "axes[0].imshow(image)\n",
    "fig.colorbar(axes[1].imshow(grads_eval,cmap=\"turbo\"))\n",
    "plt.savefig('panda_saliency_maps.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a01dca6-d532-450c-bbc2-c17096410ac5",
   "metadata": {},
   "source": [
    "This concludes our walkthrough of saliency maps. You can try to replace the sample image and swap out the [pre-trained models](https://www.tensorflow.org/api_docs/python/tf/keras/applications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40986a5b-ee96-40ef-bbed-80892e765a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.10.0 Python 3.9 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.10-cpu-py39-ubuntu20.04-sagemaker-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
